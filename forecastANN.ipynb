{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  Hour  DryBulb  DewPnt  SYSLoad   NumDate\n",
      "0  2004-01-01 00:00:00.0     1       37      25    12230  732000.0\n",
      "1  2004-01-01 00:00:00.0     2       37      25    11534  732000.0\n",
      "2  2004-01-01 00:00:00.0     3       39      24    11038  732000.0\n",
      "3  2004-01-01 00:00:00.0     4       38      22    10777  732000.0\n",
      "4  2004-01-01 00:00:00.0     5       37      20    10764  732000.0\n"
     ]
    }
   ],
   "source": [
    "#read data from csv file\n",
    "data=pd.read_csv('Book3.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       datetime64[ns]\n",
       "Holiday            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve list of holidays\n",
    "hdata=pd.read_excel('Holidays.xls')\n",
    "hdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2004-01-01\n",
       "1   2004-01-19\n",
       "2   2004-02-16\n",
       "3   2004-05-31\n",
       "4   2004-07-05\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays=hdata.Date\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       datetime64[ns]\n",
       "Hour                int64\n",
       "DryBulb             int64\n",
       "DewPnt              int64\n",
       "SYSLoad             int64\n",
       "NumDate           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert dates to datetime data type\n",
    "data['Date']=pd.to_datetime(data['Date'])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    3\n",
       "3    3\n",
       "4    3\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the day of the week for each date in the data\n",
    "dayofweek=data.Date.dt.weekday\n",
    "dayofweek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isworkday = np.in1d(dayofweek,[0,1,2,3,4]) & ~np.in1d(data['Date'],holidays)\n",
    "isworkday[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevdaysamehour=np.hstack(((np.ones(24)*-1),(data['SYSLoad'][0:-24])))\n",
    "prevdaysamehour[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52608,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevweeksamehour=np.hstack(((np.ones(168)*-1),(data['SYSLoad'][0:-168])))\n",
    "prevweeksamehour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52608,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.signal\n",
    "#By using the lfilter method get the previous 24 hour averrage temperature \n",
    "prev24houravg = scipy.signal.lfilter(np.ones(24) / 24, 1, data['SYSLoad'])\n",
    "prev24houravg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 52608)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put all the input data together into a single matrix\n",
    "X = np.vstack((data['DryBulb'],data['DewPnt'],data['Hour'],dayofweek,isworkday,prevweeksamehour,prevdaysamehour,prev24houravg))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52608, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.transpose(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-767b79d7bf3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnumcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "numcols=X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52440, 8)\n",
      "(52440, 6)\n"
     ]
    }
   ],
   "source": [
    "#Take out the first 168 indexes because they have null values\n",
    "X=X[168:,:]\n",
    "data=data[168:]\n",
    "print(X.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34896, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the training index that will be used to split the data into train and test\n",
    "trainInd = data.Date < dt.datetime(2008, 1, 1) \n",
    "trainX = X[trainInd,:]\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afzal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34896, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign the training outputs\n",
    "trainY=data.SYSLoad[trainInd]\n",
    "trainY=trainY.as_matrix(columns=None)\n",
    "trainY = trainY.reshape((trainY.shape[0], 1))\n",
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.0000000e+00, -5.0000000e+00,  2.4000000e+01,  2.0000000e+00,\n",
       "        1.0000000e+00,  1.3253000e+04,  1.3827000e+04,  1.6115375e+04])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the range for the validation data\n",
    "validX=X[34896:43680]\n",
    "validX.shape\n",
    "validX[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afzal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([15438], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validY=data.SYSLoad[34896:43680]\n",
    "validY=validY.as_matrix(columns=None)\n",
    "validY = validY.reshape((validY.shape[0], 1))\n",
    "validY[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7000000e+01, 2.4000000e+01, 2.4000000e+01, 3.0000000e+00,\n",
       "       1.0000000e+00, 1.3803000e+04, 1.4466000e+04, 1.5745625e+04])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testInd = data.Date>= dt.datetime(2009, 1, 1)\n",
    "testX=X[testInd,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afzal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13953], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY=data.SYSLoad[testInd]\n",
    "testY=testY.as_matrix(columns=None)\n",
    "testY = testY.reshape((testY.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\afzal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "model2 =Sequential()\n",
    "model2.add(Dense(60,activation='relu' ,input_shape=(numcols,)))\n",
    "model2.add(Dense(60,activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "model2.compile(optimizer='adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\afzal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "34896/34896 [==============================] - 4s 126us/step - loss: 1437.5823\n",
      "Epoch 2/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 775.7344\n",
      "Epoch 3/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 755.5017\n",
      "Epoch 4/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 733.6473\n",
      "Epoch 5/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 728.6479\n",
      "Epoch 6/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 718.9223\n",
      "Epoch 7/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 713.6256\n",
      "Epoch 8/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 710.5816\n",
      "Epoch 9/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 705.9831\n",
      "Epoch 10/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 709.7126\n",
      "Epoch 11/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 695.7182\n",
      "Epoch 12/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 702.0945\n",
      "Epoch 13/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 698.1790\n",
      "Epoch 14/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 694.2843: 0s - loss: 697.\n",
      "Epoch 15/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 689.4763\n",
      "Epoch 16/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 689.6992\n",
      "Epoch 17/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 688.1629\n",
      "Epoch 18/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 689.4368\n",
      "Epoch 19/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 686.1820\n",
      "Epoch 20/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 689.9171\n",
      "Epoch 21/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 685.8392\n",
      "Epoch 22/500\n",
      "34896/34896 [==============================] - 1s 21us/step - loss: 682.1134\n",
      "Epoch 23/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 681.2638\n",
      "Epoch 24/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 678.1278\n",
      "Epoch 25/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 671.1435\n",
      "Epoch 26/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 682.3821\n",
      "Epoch 27/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 674.5719\n",
      "Epoch 28/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 674.0782\n",
      "Epoch 29/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 672.2640\n",
      "Epoch 30/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 665.9705\n",
      "Epoch 31/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 670.6891\n",
      "Epoch 32/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 669.4093\n",
      "Epoch 33/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 665.1294\n",
      "Epoch 34/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 657.5832\n",
      "Epoch 35/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 661.9131\n",
      "Epoch 36/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 663.4759\n",
      "Epoch 37/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 656.3332\n",
      "Epoch 38/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 658.6078\n",
      "Epoch 39/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 658.0593\n",
      "Epoch 40/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 661.7521\n",
      "Epoch 41/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 654.4236\n",
      "Epoch 42/500\n",
      "34896/34896 [==============================] - 1s 19us/step - loss: 659.2920\n",
      "Epoch 43/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 652.5553\n",
      "Epoch 44/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 659.1462\n",
      "Epoch 45/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 655.4865\n",
      "Epoch 46/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 660.6549\n",
      "Epoch 47/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 654.4546\n",
      "Epoch 48/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 644.1192\n",
      "Epoch 49/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 649.3578\n",
      "Epoch 50/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 644.4429\n",
      "Epoch 51/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 642.9793\n",
      "Epoch 52/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 649.1467\n",
      "Epoch 53/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 651.1974\n",
      "Epoch 54/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 649.7958\n",
      "Epoch 55/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 643.4042\n",
      "Epoch 56/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 646.5635\n",
      "Epoch 57/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 645.3547\n",
      "Epoch 58/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 649.0788\n",
      "Epoch 59/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 647.9993\n",
      "Epoch 60/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 648.6836\n",
      "Epoch 61/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 647.9647\n",
      "Epoch 62/500\n",
      "34896/34896 [==============================] - 1s 19us/step - loss: 641.5176\n",
      "Epoch 63/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 643.8084\n",
      "Epoch 64/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 641.3903\n",
      "Epoch 65/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 642.8756\n",
      "Epoch 66/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 638.5141\n",
      "Epoch 67/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 639.3717\n",
      "Epoch 68/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 641.8669\n",
      "Epoch 69/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 643.9934\n",
      "Epoch 70/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 644.6782\n",
      "Epoch 71/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 639.0898\n",
      "Epoch 72/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 643.4474\n",
      "Epoch 73/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 636.0810\n",
      "Epoch 74/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 639.0459\n",
      "Epoch 75/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 643.3182\n",
      "Epoch 76/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 636.0253\n",
      "Epoch 77/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 637.6933\n",
      "Epoch 78/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 634.6751\n",
      "Epoch 79/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 639.3985\n",
      "Epoch 80/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 635.4148\n",
      "Epoch 81/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 630.2765\n",
      "Epoch 82/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 635.9309\n",
      "Epoch 83/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 634.6220\n",
      "Epoch 84/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 638.0774\n",
      "Epoch 85/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 629.3063\n",
      "Epoch 86/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 631.7120\n",
      "Epoch 87/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 629.4058\n",
      "Epoch 88/500\n",
      "34896/34896 [==============================] - ETA: 0s - loss: 628.891 - 1s 16us/step - loss: 629.3579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 631.3166\n",
      "Epoch 90/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 631.1633\n",
      "Epoch 91/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 632.1023\n",
      "Epoch 92/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 628.9337\n",
      "Epoch 93/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 621.3026\n",
      "Epoch 94/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 623.9249\n",
      "Epoch 95/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 620.8763\n",
      "Epoch 96/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 626.2482\n",
      "Epoch 97/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 620.9637\n",
      "Epoch 98/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 619.7080\n",
      "Epoch 99/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 617.1887\n",
      "Epoch 100/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 617.4015\n",
      "Epoch 101/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 616.3213\n",
      "Epoch 102/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 618.2088\n",
      "Epoch 103/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 621.0094\n",
      "Epoch 104/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 617.5365\n",
      "Epoch 105/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 613.2285\n",
      "Epoch 106/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 618.8721\n",
      "Epoch 107/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 608.7706\n",
      "Epoch 108/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 613.5589\n",
      "Epoch 109/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 613.5630\n",
      "Epoch 110/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 610.1490\n",
      "Epoch 111/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 607.5881\n",
      "Epoch 112/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 610.8399\n",
      "Epoch 113/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 610.7963\n",
      "Epoch 114/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 606.3063\n",
      "Epoch 115/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 604.6635\n",
      "Epoch 116/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 598.5309\n",
      "Epoch 117/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 601.9215\n",
      "Epoch 118/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 610.1388\n",
      "Epoch 119/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 606.3308\n",
      "Epoch 120/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 598.3071\n",
      "Epoch 121/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 599.2573\n",
      "Epoch 122/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 600.3141\n",
      "Epoch 123/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 599.1081\n",
      "Epoch 124/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 596.6764\n",
      "Epoch 125/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 597.9188\n",
      "Epoch 126/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 592.2452\n",
      "Epoch 127/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 592.7095\n",
      "Epoch 128/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 592.9757\n",
      "Epoch 129/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 589.1678\n",
      "Epoch 130/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 585.3850\n",
      "Epoch 131/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 586.3069\n",
      "Epoch 132/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 587.1415\n",
      "Epoch 133/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 588.2373\n",
      "Epoch 134/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 581.0525\n",
      "Epoch 135/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 593.2322\n",
      "Epoch 136/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 585.6892\n",
      "Epoch 137/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 585.9882\n",
      "Epoch 138/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 593.4106\n",
      "Epoch 139/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 585.1996\n",
      "Epoch 140/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 593.3021\n",
      "Epoch 141/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 588.2693\n",
      "Epoch 142/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 582.6005\n",
      "Epoch 143/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 576.0368\n",
      "Epoch 144/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 578.1751\n",
      "Epoch 145/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 579.6145\n",
      "Epoch 146/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 574.1532\n",
      "Epoch 147/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 587.2704\n",
      "Epoch 148/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 571.2273\n",
      "Epoch 149/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 578.1795\n",
      "Epoch 150/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 576.1716\n",
      "Epoch 151/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 573.8648\n",
      "Epoch 152/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 569.8794\n",
      "Epoch 153/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 576.7820\n",
      "Epoch 154/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 575.2162\n",
      "Epoch 155/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 573.6225\n",
      "Epoch 156/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 566.1776\n",
      "Epoch 157/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 564.8351\n",
      "Epoch 158/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 566.5036\n",
      "Epoch 159/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 575.1101\n",
      "Epoch 160/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 575.4153\n",
      "Epoch 161/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 572.3931\n",
      "Epoch 162/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 562.8607\n",
      "Epoch 163/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 571.5381\n",
      "Epoch 164/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 564.4569\n",
      "Epoch 165/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 560.0532\n",
      "Epoch 166/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 563.7389\n",
      "Epoch 167/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 567.1349\n",
      "Epoch 168/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 564.3600\n",
      "Epoch 169/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 563.6074\n",
      "Epoch 170/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 564.3768\n",
      "Epoch 171/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 560.7339\n",
      "Epoch 172/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 563.0907\n",
      "Epoch 173/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 569.9813\n",
      "Epoch 174/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 564.9305\n",
      "Epoch 175/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 562.3918\n",
      "Epoch 176/500\n",
      "34896/34896 [==============================] - 0s 13us/step - loss: 561.1356\n",
      "Epoch 177/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 560.5564\n",
      "Epoch 178/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 554.6079\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34896/34896 [==============================] - 1s 16us/step - loss: 565.3829\n",
      "Epoch 180/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 567.6879\n",
      "Epoch 181/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 556.3177\n",
      "Epoch 182/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 555.7222\n",
      "Epoch 183/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 556.7509: 0s - loss: 556.\n",
      "Epoch 184/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 560.3940\n",
      "Epoch 185/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 556.6374\n",
      "Epoch 186/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 552.7369\n",
      "Epoch 187/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 556.6111\n",
      "Epoch 188/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 573.4341\n",
      "Epoch 189/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 551.0223\n",
      "Epoch 190/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 558.6103\n",
      "Epoch 191/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 552.0159\n",
      "Epoch 192/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 555.5030\n",
      "Epoch 193/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 552.4696\n",
      "Epoch 194/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 554.4416\n",
      "Epoch 195/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 547.0610\n",
      "Epoch 196/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 551.4342\n",
      "Epoch 197/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 554.9646\n",
      "Epoch 198/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 554.1222\n",
      "Epoch 199/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 553.0626\n",
      "Epoch 200/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 554.0556\n",
      "Epoch 201/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 547.4014\n",
      "Epoch 202/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 554.7097\n",
      "Epoch 203/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 550.8572\n",
      "Epoch 204/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 549.7495\n",
      "Epoch 205/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 551.0139\n",
      "Epoch 206/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 550.3632\n",
      "Epoch 207/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 558.6130\n",
      "Epoch 208/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 548.2570\n",
      "Epoch 209/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 545.6284\n",
      "Epoch 210/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 552.0466\n",
      "Epoch 211/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 544.0714\n",
      "Epoch 212/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 544.5195\n",
      "Epoch 213/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 547.5748\n",
      "Epoch 214/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 552.7160\n",
      "Epoch 215/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 546.8288\n",
      "Epoch 216/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 542.3094\n",
      "Epoch 217/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 549.6153\n",
      "Epoch 218/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 547.1986\n",
      "Epoch 219/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 545.4681\n",
      "Epoch 220/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 547.8569\n",
      "Epoch 221/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 545.0588\n",
      "Epoch 222/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 544.1392\n",
      "Epoch 223/500\n",
      "34896/34896 [==============================] - 1s 19us/step - loss: 540.6623\n",
      "Epoch 224/500\n",
      "34896/34896 [==============================] - 1s 20us/step - loss: 551.4624\n",
      "Epoch 225/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 547.3315\n",
      "Epoch 226/500\n",
      "34896/34896 [==============================] - 1s 20us/step - loss: 548.2920: 0s - loss: \n",
      "Epoch 227/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 548.2609\n",
      "Epoch 228/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 543.4960\n",
      "Epoch 229/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 543.8831\n",
      "Epoch 230/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 541.1279\n",
      "Epoch 231/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 544.4236\n",
      "Epoch 232/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 540.1370\n",
      "Epoch 233/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 542.7428\n",
      "Epoch 234/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 544.6124\n",
      "Epoch 235/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 543.8042\n",
      "Epoch 236/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 538.1250\n",
      "Epoch 237/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 543.6473\n",
      "Epoch 238/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 543.6132\n",
      "Epoch 239/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 543.7319\n",
      "Epoch 240/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 540.0426\n",
      "Epoch 241/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 539.3432\n",
      "Epoch 242/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 553.8698\n",
      "Epoch 243/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 541.7926\n",
      "Epoch 244/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 543.5544\n",
      "Epoch 245/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 539.0965\n",
      "Epoch 246/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 537.5839\n",
      "Epoch 247/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 541.1513\n",
      "Epoch 248/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 535.1249\n",
      "Epoch 249/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 540.4794\n",
      "Epoch 250/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 542.6510\n",
      "Epoch 251/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 540.9424\n",
      "Epoch 252/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 535.5464\n",
      "Epoch 253/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 533.0883\n",
      "Epoch 254/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 543.1200\n",
      "Epoch 255/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 535.2729\n",
      "Epoch 256/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 534.0023\n",
      "Epoch 257/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 536.1635\n",
      "Epoch 258/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 534.9041\n",
      "Epoch 259/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 544.4198\n",
      "Epoch 260/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 532.8731\n",
      "Epoch 261/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 539.2764\n",
      "Epoch 262/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 536.9661\n",
      "Epoch 263/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 539.7072\n",
      "Epoch 264/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 538.2481\n",
      "Epoch 265/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 534.4886\n",
      "Epoch 266/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 534.8695\n",
      "Epoch 267/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 535.5899\n",
      "Epoch 268/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 540.0313\n",
      "Epoch 269/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 533.3960\n",
      "Epoch 270/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 535.8087\n",
      "Epoch 271/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 535.3015\n",
      "Epoch 272/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 533.0175\n",
      "Epoch 273/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 537.8091\n",
      "Epoch 274/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 540.1914\n",
      "Epoch 275/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 531.1890\n",
      "Epoch 276/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 536.5936\n",
      "Epoch 277/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 533.9094\n",
      "Epoch 278/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 531.3479\n",
      "Epoch 279/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 536.0114\n",
      "Epoch 280/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 533.7586\n",
      "Epoch 281/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 538.0587\n",
      "Epoch 282/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 530.1326\n",
      "Epoch 283/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 537.0967\n",
      "Epoch 284/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 532.5362\n",
      "Epoch 285/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 540.9547\n",
      "Epoch 286/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 528.3420\n",
      "Epoch 287/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 537.6811\n",
      "Epoch 288/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 531.0949\n",
      "Epoch 289/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 532.2922\n",
      "Epoch 290/500\n",
      "34896/34896 [==============================] - 1s 19us/step - loss: 530.7424\n",
      "Epoch 291/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 532.7804\n",
      "Epoch 292/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 533.7666\n",
      "Epoch 293/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 529.2549\n",
      "Epoch 294/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 527.2050\n",
      "Epoch 295/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 530.9445\n",
      "Epoch 296/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 533.8728\n",
      "Epoch 297/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 526.3128\n",
      "Epoch 298/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 529.9852\n",
      "Epoch 299/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 527.2976\n",
      "Epoch 300/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 533.4750\n",
      "Epoch 301/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 524.1644\n",
      "Epoch 302/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 527.8730\n",
      "Epoch 303/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 532.6155\n",
      "Epoch 304/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 533.6851\n",
      "Epoch 305/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 526.2357\n",
      "Epoch 306/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 526.9945\n",
      "Epoch 307/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 522.3902\n",
      "Epoch 308/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 530.4056\n",
      "Epoch 309/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 527.6958\n",
      "Epoch 310/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.6961\n",
      "Epoch 311/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 526.0272\n",
      "Epoch 312/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 529.0280\n",
      "Epoch 313/500\n",
      "34896/34896 [==============================] - 1s 19us/step - loss: 528.2098\n",
      "Epoch 314/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.0343\n",
      "Epoch 315/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 524.8404\n",
      "Epoch 316/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 520.8334\n",
      "Epoch 317/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.1988\n",
      "Epoch 318/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 526.2208\n",
      "Epoch 319/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 524.7074\n",
      "Epoch 320/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 524.1233\n",
      "Epoch 321/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 528.1468\n",
      "Epoch 322/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.1236\n",
      "Epoch 323/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 524.2110\n",
      "Epoch 324/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 524.6757\n",
      "Epoch 325/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 521.1483\n",
      "Epoch 326/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.3217\n",
      "Epoch 327/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 525.8504\n",
      "Epoch 328/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 526.2547\n",
      "Epoch 329/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 522.5948\n",
      "Epoch 330/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 524.6923\n",
      "Epoch 331/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 522.9172\n",
      "Epoch 332/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 526.2688\n",
      "Epoch 333/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.5163\n",
      "Epoch 334/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 519.6707\n",
      "Epoch 335/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 520.1109\n",
      "Epoch 336/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 515.9105\n",
      "Epoch 337/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 517.1113\n",
      "Epoch 338/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 522.3071\n",
      "Epoch 339/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 522.2218\n",
      "Epoch 340/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 523.7661\n",
      "Epoch 341/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 518.8523\n",
      "Epoch 342/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 525.9862\n",
      "Epoch 343/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 524.3344\n",
      "Epoch 344/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 517.7715\n",
      "Epoch 345/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 518.1494\n",
      "Epoch 346/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 518.4681\n",
      "Epoch 347/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 521.8845\n",
      "Epoch 348/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 518.2927\n",
      "Epoch 349/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 517.4056\n",
      "Epoch 350/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 515.4099\n",
      "Epoch 351/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 518.0539\n",
      "Epoch 352/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 519.7291\n",
      "Epoch 353/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 516.8212\n",
      "Epoch 354/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 516.4790\n",
      "Epoch 355/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 517.1833\n",
      "Epoch 356/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 517.2414\n",
      "Epoch 357/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 521.0799\n",
      "Epoch 358/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34896/34896 [==============================] - 1s 16us/step - loss: 514.3698\n",
      "Epoch 359/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 521.1044\n",
      "Epoch 360/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.9249\n",
      "Epoch 361/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 520.0229\n",
      "Epoch 362/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 515.2088\n",
      "Epoch 363/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 514.5308\n",
      "Epoch 364/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 524.6797\n",
      "Epoch 365/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 515.1491\n",
      "Epoch 366/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 512.3182\n",
      "Epoch 367/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 518.2856\n",
      "Epoch 368/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 515.2217\n",
      "Epoch 369/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 516.6897\n",
      "Epoch 370/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.3648\n",
      "Epoch 371/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 506.0891\n",
      "Epoch 372/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 523.7260\n",
      "Epoch 373/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.8958\n",
      "Epoch 374/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.6066\n",
      "Epoch 375/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 514.6939\n",
      "Epoch 376/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.8658\n",
      "Epoch 377/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 511.4779\n",
      "Epoch 378/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 519.3626\n",
      "Epoch 379/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 515.5684\n",
      "Epoch 380/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 512.4526\n",
      "Epoch 381/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 518.8037\n",
      "Epoch 382/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 511.7847\n",
      "Epoch 383/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.8634\n",
      "Epoch 384/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 514.4727\n",
      "Epoch 385/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 512.1890\n",
      "Epoch 386/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 514.2110\n",
      "Epoch 387/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 520.8446\n",
      "Epoch 388/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 511.6669\n",
      "Epoch 389/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.8005\n",
      "Epoch 390/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 511.5399\n",
      "Epoch 391/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 514.4104\n",
      "Epoch 392/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 515.4630\n",
      "Epoch 393/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.5026\n",
      "Epoch 394/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 515.4566\n",
      "Epoch 395/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.2335\n",
      "Epoch 396/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 512.5342\n",
      "Epoch 397/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 508.2686\n",
      "Epoch 398/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.3723\n",
      "Epoch 399/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 514.5482\n",
      "Epoch 400/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.5638\n",
      "Epoch 401/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.9540\n",
      "Epoch 402/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.3274\n",
      "Epoch 403/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 507.6744\n",
      "Epoch 404/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.1649\n",
      "Epoch 405/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 511.7306\n",
      "Epoch 406/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 510.0427: 0s - loss: 507.218\n",
      "Epoch 407/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.5843\n",
      "Epoch 408/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.4106\n",
      "Epoch 409/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.9845\n",
      "Epoch 410/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 517.2026\n",
      "Epoch 411/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 506.5690\n",
      "Epoch 412/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.4022\n",
      "Epoch 413/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 507.3633\n",
      "Epoch 414/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.6195\n",
      "Epoch 415/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 512.2660\n",
      "Epoch 416/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 506.5583\n",
      "Epoch 417/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 503.7979\n",
      "Epoch 418/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.8391\n",
      "Epoch 419/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 512.1757\n",
      "Epoch 420/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 515.5744\n",
      "Epoch 421/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.1013\n",
      "Epoch 422/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 514.4178\n",
      "Epoch 423/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.3572\n",
      "Epoch 424/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 511.1006\n",
      "Epoch 425/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 508.8932\n",
      "Epoch 426/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.1190\n",
      "Epoch 427/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.5122\n",
      "Epoch 428/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.3625\n",
      "Epoch 429/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 514.9662\n",
      "Epoch 430/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 511.9604\n",
      "Epoch 431/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 512.5708\n",
      "Epoch 432/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 512.7610\n",
      "Epoch 433/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 510.0399\n",
      "Epoch 434/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 508.4445\n",
      "Epoch 435/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 511.7996\n",
      "Epoch 436/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 507.6783\n",
      "Epoch 437/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 510.8191\n",
      "Epoch 438/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 514.8912\n",
      "Epoch 439/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 507.4628\n",
      "Epoch 440/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 510.2556\n",
      "Epoch 441/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 511.1420\n",
      "Epoch 442/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 513.4415\n",
      "Epoch 443/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 504.3355\n",
      "Epoch 444/500\n",
      "34896/34896 [==============================] - 1s 14us/step - loss: 517.2835\n",
      "Epoch 445/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 506.8037\n",
      "Epoch 446/500\n",
      "34896/34896 [==============================] - 0s 14us/step - loss: 510.0246\n",
      "Epoch 447/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 512.2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 509.6692\n",
      "Epoch 449/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 512.7595\n",
      "Epoch 450/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 506.7209\n",
      "Epoch 451/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 507.0260\n",
      "Epoch 452/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 513.1214\n",
      "Epoch 453/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 507.6010\n",
      "Epoch 454/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 511.1279\n",
      "Epoch 455/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 508.7082\n",
      "Epoch 456/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 511.1588\n",
      "Epoch 457/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.3634\n",
      "Epoch 458/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 508.4251\n",
      "Epoch 459/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 501.4799\n",
      "Epoch 460/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 502.8911\n",
      "Epoch 461/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 506.3240\n",
      "Epoch 462/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 507.5085\n",
      "Epoch 463/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 509.2274\n",
      "Epoch 464/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 506.8328\n",
      "Epoch 465/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 503.3777\n",
      "Epoch 466/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.8610\n",
      "Epoch 467/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.7082\n",
      "Epoch 468/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 505.9701\n",
      "Epoch 469/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 512.9075\n",
      "Epoch 470/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 507.9001\n",
      "Epoch 471/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 510.9300\n",
      "Epoch 472/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 504.6271\n",
      "Epoch 473/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.2381\n",
      "Epoch 474/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 502.2847\n",
      "Epoch 475/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 514.3010\n",
      "Epoch 476/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 502.5035\n",
      "Epoch 477/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.2017\n",
      "Epoch 478/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 504.4395\n",
      "Epoch 479/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 503.1765\n",
      "Epoch 480/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 501.4381\n",
      "Epoch 481/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 508.2760\n",
      "Epoch 482/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.6969\n",
      "Epoch 483/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 503.6553\n",
      "Epoch 484/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 505.3966\n",
      "Epoch 485/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.9361\n",
      "Epoch 486/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 502.2018\n",
      "Epoch 487/500\n",
      "34896/34896 [==============================] - 1s 19us/step - loss: 505.7639\n",
      "Epoch 488/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 506.6670\n",
      "Epoch 489/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 508.0911\n",
      "Epoch 490/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 503.4936\n",
      "Epoch 491/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 501.3743\n",
      "Epoch 492/500\n",
      "34896/34896 [==============================] - 1s 18us/step - loss: 511.1778\n",
      "Epoch 493/500\n",
      "34896/34896 [==============================] - 1s 17us/step - loss: 505.8386\n",
      "Epoch 494/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.1803\n",
      "Epoch 495/500\n",
      "34896/34896 [==============================] - 1s 16us/step - loss: 505.4162\n",
      "Epoch 496/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 503.9203\n",
      "Epoch 497/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 509.5312\n",
      "Epoch 498/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 501.7047\n",
      "Epoch 499/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 504.5352\n",
      "Epoch 500/500\n",
      "34896/34896 [==============================] - 1s 15us/step - loss: 497.5382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "279.7330675125122"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "history=model2.fit(trainX, trainY, batch_size=150, epochs=500,verbose=1)\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509.9725527459372"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions= model2.predict(validX,verbose=2)\n",
    "error=validY-predictions\n",
    "#calculate mean absolute error for validation set\n",
    "mae=np.mean(np.absolute(error))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2977630798206317\n"
     ]
    }
   ],
   "source": [
    "#calculate mean absolute percent error for validation set\n",
    "errorpercent=np.absolute(error)/validY\n",
    "mape=np.mean(errorpercent)*100\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451.72381419003284"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpredictions= model2.predict(testX,verbose=2)\n",
    "#calculate means absolute error for test set\n",
    "error=testY-testpredictions\n",
    "mae=np.mean(np.absolute(error))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.062371216737978\n"
     ]
    }
   ],
   "source": [
    "#calulcate mean absolute percent error for test set\n",
    "errorpercent=np.absolute(error)/testY\n",
    "mape=np.mean(errorpercent)*100\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7000000e+01, 2.2000000e+01, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.2153000e+04, 1.2428000e+04, 1.4963375e+04])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plot the mean absolute percent error as a function of the number of epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
